{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train-chihuaha.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FK8Vv-EJBG8s"},"source":["## Training deteksi Chihuahuya\n"]},{"cell_type":"code","metadata":{"id":"5NpuOj8tCN-P"},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUh-tZas_h4e","executionInfo":{"status":"ok","timestamp":1621314473341,"user_tz":-420,"elapsed":65499,"user":{"displayName":"ANDREW FIRMAN SAPUTRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIhnErFJbiXJmBEzXYV-diykWfSbdSsX6mWVU92g=s64","userId":"02767248163102407760"}},"outputId":"68e0db75-b7ba-461e-d8e9-e6c5bd8d2e3f"},"source":["!pip install tensorflow-gpu==2.0.0\n","# %tensorflow_version 2.0.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/eb/bc0784af18f612838f90419cf4805c37c20ddb957f5ffe0c42144562dcfa/tensorflow_gpu-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (380.8MB)\n","\u001b[K     |████████████████████████████████| 380.8MB 47kB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.36.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.1.2)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 33.2MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (3.3.0)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.12.1)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 30.0MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.32.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.12.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.19.5)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (3.12.4)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.10.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.30.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.3.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (56.1.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2020.12.5)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.4.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=8c7e122639a8875e141bd8cf5f103e68c583e6121f62cc461d7c9ad6b556da41\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, keras-applications, gast, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cyHTqhnfB83s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621314482372,"user_tz":-420,"elapsed":74524,"user":{"displayName":"ANDREW FIRMAN SAPUTRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIhnErFJbiXJmBEzXYV-diykWfSbdSsX6mWVU92g=s64","userId":"02767248163102407760"}},"outputId":"32dd68f9-53ca-4e0e-cbcd-666cf3841de8"},"source":["!pip install keras==2.3.1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting keras==2.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\r\u001b[K     |▉                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 26.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 31.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 33.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 34.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 35.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 30.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 33.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 33.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 33.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 33.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 33.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 33.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 33.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 33.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pnOBGYtRCDSo"},"source":["import os\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OovART_SOA75","executionInfo":{"status":"ok","timestamp":1621314686438,"user_tz":-420,"elapsed":278578,"user":{"displayName":"ANDREW FIRMAN SAPUTRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIhnErFJbiXJmBEzXYV-diykWfSbdSsX6mWVU92g=s64","userId":"02767248163102407760"}},"outputId":"db13754b-29e1-45a0-9b48-8277939f0d17"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DoH_jSWSCZcz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621314686440,"user_tz":-420,"elapsed":278573,"user":{"displayName":"ANDREW FIRMAN SAPUTRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIhnErFJbiXJmBEzXYV-diykWfSbdSsX6mWVU92g=s64","userId":"02767248163102407760"}},"outputId":"bd53f3af-58c9-4473-ef57-8cc6e8203628"},"source":["# Root directory dari project\n","ROOT_DIR = os.path.abspath(\"/content/drive/MyDrive/Deep Learning/Tugas Kelompok DL/Tugas Implementasi Mask RCNN/Colab/Mask_RCNN-master\")\n","print(ROOT_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Deep Learning/Tugas Kelompok DL/Tugas Implementasi Mask RCNN/Colab/Mask_RCNN-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lF7fdRfmDScT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621314692150,"user_tz":-420,"elapsed":284276,"user":{"displayName":"ANDREW FIRMAN SAPUTRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIhnErFJbiXJmBEzXYV-diykWfSbdSsX6mWVU92g=s64","userId":"02767248163102407760"}},"outputId":"67f27add-d293-4819-ac7e-e1b02484b120"},"source":["# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","\n","# Path to trained weights file\n","COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n","\n","# Directory to save logs and model checkpoints, if not provided\n","# through the command line argument --logs\n","DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WmedOotqDblg"},"source":["class ChihuahuaConfig(Config):\n","    \"\"\"Configuration for training on the balloon dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"chihuahua\"\n","\n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 2\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + balloon\n","\n","    # Number of training steps per epoch\n","    STEPS_PER_EPOCH = 100\n","\n","    # Skip detections with < 90% confidence\n","    DETECTION_MIN_CONFIDENCE = 0.9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaDw2PUmDkox"},"source":["class ChihuahuaDataset(utils.Dataset):\n","\n","    def load_chihuahua(self, dataset_dir, subset):\n","        # Add classes. We have only one class to add.\n","        self.add_class(\"chihuahua\", 1, \"chihuaha\")\n","\n","        # Train or validation dataset?\n","        assert subset in [\"train\", \"val\"]\n","        dataset_dir = os.path.join(dataset_dir, subset)\n","\n","        # Load annotations\n","        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n","        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n","        #   'regions': {\n","        #       '0': {\n","        #           'region_attributes': {},\n","        #           'shape_attributes': {\n","        #               'all_points_x': [...],\n","        #               'all_points_y': [...],\n","        #               'name': 'polygon'}},\n","        #       ... more regions ...\n","        #   },\n","        #   'size': 100202\n","        # }\n","        # We mostly care about the x and y coordinates of each region\n","        # Note: In VIA 2.0, regions was changed from a dict to a list.\n","        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n","        annotations = list(annotations.values())  # don't need the dict keys\n","\n","        # The VIA tool saves images in the JSON even if they don't have any\n","        # annotations. Skip unannotated images.\n","        annotations = [a for a in annotations if a['regions']]\n","\n","        # Add images\n","        for a in annotations:\n","            # Get the x, y coordinaets of points of the polygons that make up\n","            # the outline of each object instance. These are stores in the\n","            # shape_attributes (see json format above)\n","            # The if condition is needed to support VIA versions 1.x and 2.x.\n","            if type(a['regions']) is dict:\n","                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n","            else:\n","                polygons = [r['shape_attributes'] for r in a['regions']] \n","\n","            # load_mask() needs the image size to convert polygons to masks.\n","            # Unfortunately, VIA doesn't include it in JSON, so we must read\n","            # the image. This is only managable since the dataset is tiny.\n","            image_path = os.path.join(dataset_dir, a['filename'])\n","            image = skimage.io.imread(image_path)\n","            height, width = image.shape[:2]\n","\n","            self.add_image(\n","                \"chihuahua\",\n","                image_id=a['filename'],  # use file name as a unique image id\n","                path=image_path,\n","                width=width, height=height,\n","                polygons=polygons)\n","\n","    def load_mask(self, image_id):\n","        \"\"\"Generate instance masks for an image.\n","       Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        # If not a balloon dataset image, delegate to parent class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != \"chihuahua\":\n","            return super(self.__class__, self).load_mask(image_id)\n","\n","        # Convert polygons to a bitmap mask of shape\n","        # [height, width, instance_count]\n","        info = self.image_info[image_id]\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n","                        dtype=np.uint8)\n","        for i, p in enumerate(info[\"polygons\"]):\n","            # Get indexes of pixels inside the polygon and set them to 1\n","            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n","            mask[rr, cc, i] = 1\n","\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"chihuahua\":\n","            return info[\"path\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzQwsdbKEYva"},"source":["def train(model):\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = ChihuahuaDataset()\n","    dataset_train.load_chihuahua(dataset, \"train\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = ChihuahuaDataset()\n","    dataset_val.load_chihuahua(dataset, \"val\")\n","    dataset_val.prepare()\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=30,\n","                layers='heads')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BpgspRgEcV3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621318898462,"user_tz":-420,"elapsed":4490569,"user":{"displayName":"ANDREW FIRMAN SAPUTRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIhnErFJbiXJmBEzXYV-diykWfSbdSsX6mWVU92g=s64","userId":"02767248163102407760"}},"outputId":"4908650c-313a-4f70-8515-9d3242587fd0"},"source":["dataset = ROOT_DIR + '/datasets/chihuahua/'\n","\n","# parameter untuk weights\n","# 'coco: load pretrained weights dari coco\n","# 'imagenet': load pretrained weights dari imagenet\n","# 'last': load pretrained weights dari proses training (belum selesai) yang terbaru\n","weights = 'last'\n","logs = DEFAULT_LOGS_DIR\n","\n","print(\"Weights: \", weights)\n","print(\"Dataset: \", dataset)\n","print(\"Logs: \", logs)\n","\n","# Configurations\n","config = ChihuahuaConfig()\n","\n","# Create model\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                              model_dir=logs)\n","\n","\n","# Select weights file to load\n","if weights.lower() == \"coco\":\n","    weights_path = COCO_WEIGHTS_PATH\n","    if not os.path.exists(weights_path):\n","        utils.download_trained_weights(weights_path)\n","elif weights.lower() == \"last\":\n","    # Find last trained weights\n","    weights_path = model.find_last()\n","elif weights.lower() == \"imagenet\":\n","    # Start from ImageNet trained weights\n","    weights_path = model.get_imagenet_weights()\n","else:\n","    weights_path = weights\n","\n","# Load weights\n","print(\"Loading weights \", weights_path)\n","if weights.lower() == \"coco\":\n","    # Exclude the last layers because they require a matching\n","    # number of classes\n","    model.load_weights(weights_path, by_name=True, exclude=[\n","        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","        \"mrcnn_bbox\", \"mrcnn_mask\"])\n","else:\n","    model.load_weights(weights_path, by_name=True)\n","\n","# Train or evaluate\n","train(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Weights:  coco\n","Dataset:  /content/drive/MyDrive/Deep Learning/Tugas Kelompok DL/Tugas Implementasi Mask RCNN/Colab/Mask_RCNN-master/datasets/chihuahua/\n","Logs:  /content/drive/MyDrive/Deep Learning/Tugas Kelompok DL/Tugas Implementasi Mask RCNN/Colab/Mask_RCNN-master/logs\n","Loading weights  /content/drive/MyDrive/Deep Learning/Tugas Kelompok DL/Tugas Implementasi Mask RCNN/Colab/Mask_RCNN-master/mask_rcnn_coco.h5\n","Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/drive/MyDrive/Deep Learning/Tugas Kelompok DL/Tugas Implementasi Mask RCNN/Colab/Mask_RCNN-master/logs/chihuahua20210518T0511/mask_rcnn_chihuahua_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... can't pickle _thread.RLock objects\n","Epoch 1/30\n","100/100 [==============================] - 198s 2s/step - loss: 1.8580 - val_loss: 2.0274\n","Epoch 2/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.8448 - val_loss: 1.1297\n","Epoch 3/30\n","100/100 [==============================] - 136s 1s/step - loss: 0.5331 - val_loss: 1.0143\n","Epoch 4/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.3777 - val_loss: 1.2566\n","Epoch 5/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.3393 - val_loss: 1.3711\n","Epoch 6/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.2865 - val_loss: 1.2481\n","Epoch 7/30\n","100/100 [==============================] - 138s 1s/step - loss: 0.2630 - val_loss: 1.6934\n","Epoch 8/30\n","100/100 [==============================] - 138s 1s/step - loss: 0.2236 - val_loss: 0.7864\n","Epoch 9/30\n","100/100 [==============================] - 137s 1s/step - loss: 0.2055 - val_loss: 1.2105\n","Epoch 10/30\n","100/100 [==============================] - 136s 1s/step - loss: 0.2021 - val_loss: 0.7479\n","Epoch 11/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1908 - val_loss: 0.6462\n","Epoch 12/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1714 - val_loss: 1.5134\n","Epoch 13/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1778 - val_loss: 0.9941\n","Epoch 14/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1465 - val_loss: 0.7695\n","Epoch 15/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1731 - val_loss: 1.1737\n","Epoch 16/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.1383 - val_loss: 1.3419\n","Epoch 17/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.1217 - val_loss: 0.8604\n","Epoch 18/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.1230 - val_loss: 0.8182\n","Epoch 19/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.1120 - val_loss: 0.7025\n","Epoch 20/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.1148 - val_loss: 1.3333\n","Epoch 21/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0985 - val_loss: 1.0237\n","Epoch 22/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.0818 - val_loss: 1.2202\n","Epoch 23/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.1080 - val_loss: 1.2059\n","Epoch 24/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0831 - val_loss: 1.1002\n","Epoch 25/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0656 - val_loss: 1.2292\n","Epoch 26/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0690 - val_loss: 1.8454\n","Epoch 27/30\n","100/100 [==============================] - 133s 1s/step - loss: 0.0680 - val_loss: 0.9820\n","Epoch 28/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0604 - val_loss: 0.7003\n","Epoch 29/30\n","100/100 [==============================] - 134s 1s/step - loss: 0.0614 - val_loss: 0.9849\n","Epoch 30/30\n","100/100 [==============================] - 135s 1s/step - loss: 0.0596 - val_loss: 1.2765\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MwuxSNoApjhH"},"source":[""],"execution_count":null,"outputs":[]}]}